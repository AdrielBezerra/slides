<!DOCTYPE html>
<html>
  <head>
    <title>Deep Learning using R</title>
    <meta charset="utf-8">
    <meta name="author" content="Curso-R" />
    <meta name="date" content="2019-03-24" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Deep Learning using R
### Curso-R
### 2019-03-24

---




&lt;style type="text/css"&gt;
.remark-slide-content {
    font-size: 27px;
    padding: 1em 1em 1em 1em;
}
&lt;/style&gt;

# Goals

.large[

* What are deep neural networks and how they work?
* What software we can use to train these models and how they relate to each other?
* How train deep learning models for some prediction problems?

]

---

# Requisites

.large[

* Linear regression
* Logistic regression
* R: pipe (`%&gt;%`)

]

---

# References

.large[

* [Deep Learning Book](https://www.deeplearningbook.org)
* [Deep Learning with R](https://www.manning.com/books/deep-learning-with-r)
* [Tensorflow for R Blog](https://blogs.rstudio.com/tensorflow/)
* [Keras examples](https://keras.rstudio.com/articles/examples/index.html)
* [Colah's blog](http://colah.github.io)

]

&lt;img src="imgs/dlbook.jpg" width="500" style="display: block; margin: auto;" /&gt;

---

# Why "Deep" Learning?

.large[

* We use many composite nonlinear operations, called *layers*, to learn a representation
* The number of layers is the model depth
* Nowadays we have models with more than 100 layers

]

--

## Alternative names

.large[

- layered representations learning
- hierarchical representations learning

]

---

# Layers

&lt;img src="imgs/layers.png" width="1053" style="display: block; margin: auto;" /&gt;

---

# Deep Learning

&lt;img src="imgs/structure1.png" width="709" style="display: block; margin: auto;" /&gt;


---

# Deep Learning

&lt;img src="imgs/structure2.png" width="709" style="display: block; margin: auto;" /&gt;

---

# Deep Learning

&lt;img src="imgs/structure3.png" width="709" style="display: block; margin: auto;" /&gt;

---

# Relation to Generalized Linear Models

.large[

- Linear regression: single layer neural network, no activation
- Logistic regression: single layer neural netork, logit activation

]

---

# Logistic regression

&lt;img src="imgs/glm.png" width="968" style="display: block; margin: auto;" /&gt;

---

# Deviance function

.large[

`$$D(y,\hat\mu(x)) = \sum_{i=1}^n 2\left[y_i\log\frac{y_i}{\hat\mu_i(x_i)} + (1-y_i)\log\left(\frac{1-y_i}{1-\hat\mu_i(x_i)}\right)\right]$$`

`$$= 2 D_{KL}\left(y||\hat\mu(x)\right),$$`

where `\(D_{KL}(p||q) = \sum_i p_i\log\frac{p_i}{q_i}\)` is the Kullback-Leibler divergence.

]

---

# Deep learning

&lt;img src="imgs/y1.png" width="80%" style="display: block; margin: auto;" /&gt;

.large[

- Linear transformation of `\(x\)`, add bias and add some nonlinear activation.

`$$f(x) = \sigma(wx + b)$$`

]

--

#### Loss function

.large[

`$$D_{KL}(p(x)||q(x))$$`

]

--

&lt;img src="imgs/thinking.png" width="10%" style="display: block; margin: auto;" /&gt;

---

# Optimization: Stochastic Gradient Descent

```
for(i in 1:num_epochs) {
  grads &lt;- compute_gradient(data, params)
  params &lt;- params - learning_rate * grads
}
```

---

# SGD

&lt;img src="https://user-images.githubusercontent.com/4706822/48280375-870fdd00-e43a-11e8-868d-c5afa9e7c257.png" style="width: 90%"&gt;
&lt;img src="https://user-images.githubusercontent.com/4706822/48280383-8d05be00-e43a-11e8-96e8-7f55b697ef6f.png" style="width: 90%"&gt;

---

# TensorFlow

.large[

It's a computational library

- Developed in Google Brain for neural network research
- Open Source
- Automatic Differentiation
- Uses GPU

]

&lt;img src="imgs/diff.png" width="80%" style="display: block; margin: auto;" /&gt;

---

# Tensor

(2d)


```
##       Sepal.Length Sepal.Width Petal.Length Petal.Width Species
##  [1,]          5.1         3.5          1.4         0.2       1
##  [2,]          4.9         3.0          1.4         0.2       1
##  [3,]          4.7         3.2          1.3         0.2       1
##  [4,]          4.6         3.1          1.5         0.2       1
##  [5,]          5.0         3.6          1.4         0.2       1
##  [6,]          5.4         3.9          1.7         0.4       1
##  [7,]          4.6         3.4          1.4         0.3       1
##  [8,]          5.0         3.4          1.5         0.2       1
##  [9,]          4.4         2.9          1.4         0.2       1
## [10,]          4.9         3.1          1.5         0.1       1
```

---

# Tensor

(3d)

![](https://github.com/curso-r/deep-learning-R/blob/master/3d-tensor.png?raw=true)

---

# Tensor

(4d)

&lt;img src="https://github.com/curso-r/deep-learning-R/blob/master/4d-tensor.png?raw=true" style="width: 60%"&gt;

---

# TensorFlow

.pull-left[
  ![](https://github.com/curso-r/deep-learning-R/blob/master/flow.gif?raw=true)
]

.pull-right[
  - Define the graph
  - Compile and optimize
  - Execute
  - Nodes are calculations
  - the tensors *flow* along the nodes.
]

---

# Keras

.large[

* API used to specify deep learning models in a intuitive flavor.

]

--

.large[

* Created by Fran√ßois Chollet (@fchollet).

]

&lt;img src="imgs/chollet.jpg" width="50%" style="display: block; margin: auto;" /&gt;

.large[

* Originally implemented in `python`.

]

---

# Keras + R

.large[

* R package: [`keras`](https://github.com/rstudio/keras).
* Based in [reticulate](https://github.com/rstudio/reticulate).
* Developed by JJ Allaire (CEO at RStudio).
* R-like syntax using `%&gt;%`.

]

&lt;img src="imgs/jj.jpg" width="50%" style="display: block; margin: auto;" /&gt;

---

# Keras for R

&lt;img src="imgs/keras.svg" style="display: block; margin: auto;" /&gt;

---

# Example 01

---

# Activation

&lt;img src="imgs/activation.png" width="70%" style="display: block; margin: auto;" /&gt;

---

# Activation problems

&lt;img src="imgs/derivative.png" width="40%" style="display: block; margin: auto;" /&gt;&lt;img src="imgs/sigmoid.png" width="40%" style="display: block; margin: auto;" /&gt;


---

# Example 02

---

# Example 03

---

# Convolutions

&lt;img src="https://user-images.githubusercontent.com/4706822/48281225-10281380-e43d-11e8-9879-6a7e1b51df15.gif" style="position: fixed; top: 200px; left: 50px; width: 30%"&gt;

--

&lt;img src="https://user-images.githubusercontent.com/4706822/48281225-10281380-e43d-11e8-9879-6a7e1b51df15.gif" style="position: fixed; top: 200px; left: 300px; width: 30%"&gt;

--

&lt;img src="https://user-images.githubusercontent.com/4706822/48281225-10281380-e43d-11e8-9879-6a7e1b51df15.gif" style="position: fixed; top: 200px; left: 600px; width: 30%"&gt;

---

# Convolutions

&lt;img src="imgs/convolutions.png" width="70%" style="display: block; margin: auto;" /&gt;

---

# Max Pooling 

![](https://user-images.githubusercontent.com/4706822/48281479-df94a980-e43d-11e8-9dcf-e67d7ba053e4.png)

---

# Convolutions

![](https://user-images.githubusercontent.com/4706822/48281946-6bf39c00-e43f-11e8-845c-2d08570d85a6.png)

---

# Binary Cross-Entropy

&lt;img src="imgs/binary_cross_entropy.png" width="677" style="display: block; margin: auto;" /&gt;

---

# Example 04

---

# Categorical Cross-Entropy

&lt;img src="imgs/categorical_cross_entropy.png" width="1621" style="display: block; margin: auto;" /&gt;

---

# Example 05

---


# Stalk us

- Bruna Wundervald: [brunaw.com](brunaw.com)
- Curso-R: [contato@curso-r.com](mailto:jtrecenti@curso-r.com)
- CONRE-3: [jtrecenti@conre3.org.br](mailto:jtrecenti@conre3.org.br)

## Pages: 

- https://brunaw.com
- https://curso-r.com
- https://github.com/brunaw
- https://github.com/curso-r

Presentation: https://jtrecenti.github.io/slides/emr-dl/

Code: https://github.com/jtrecenti/slides
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
